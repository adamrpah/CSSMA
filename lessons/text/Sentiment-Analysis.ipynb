{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sentiment\n",
    "\n",
    "Sentiment is one of the largest attractors of applied analysis - is this passage positive or negative? Is this person happy or unhappy? \n",
    "\n",
    "This seems like a daunting task, but in its most basic form it is relatively easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The basics of sentiment\n",
    "\n",
    "Human's use of language will always have some implied emotion and decoding that increases its quantitative appeal. However, this mapping of word to sentiment (positive or negative, how positive or negative) must be done since it doesn't already exist in written or spoken language.\n",
    "\n",
    "This mapping **must** be constructed. \n",
    "\n",
    "Different considerations are made by creators when they construct their dicionaries. If you are using a pre-built dictionary then you should spend time considering the match between the dictionary provenance and your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AFINN\n",
    "\n",
    "As a start, we will be using the AFINN sentiment dictionary (Finn Ã…rup Nielsen, \"A new ANEW: Evaluation of a word list for sentiment analysis in microblogs\", http://arxiv.org/abs/1103.2903). The larger word list is AFINN 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "afinnlist = [l.strip().split('\\t') for l in open('../data/AFINN/AFINN-111.txt').readlines()]\n",
    "afinn = {k:int(v) for k,v in afinnlist}\n",
    "list(afinn.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can do a basic test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "example_text = \"Adam is totally cool. You should come to his class\"\n",
    "for word in nltk.word_tokenize(example_text):\n",
    "    if word in afinn:\n",
    "        print(word, afinn[word])\n",
    "    else:\n",
    "        print(word, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As we can see, only word assigned a sentiment score is \"cool\".\n",
    "\n",
    "`Adam` is a proper noun, `You` is a pronoun, `his` is a possessive - so no sentiment there\n",
    "\n",
    "`is`, `should`, and `come` are the verbs - so no sentiment\n",
    "\n",
    "`to` is a preposition\n",
    "\n",
    "`class` is a noun\n",
    "\n",
    "`totally` is a different story though. It's an adverb and is modifying `cool`, which is positive. However, the sentiment of `totally` is entirely dependent on the word that it is modifying. So on its own, it it doesn't actually have a score.\n",
    "\n",
    "So we can judge that this overall text is mildly positive, there isn't that much to go on though since it's such a small piece! \n",
    "\n",
    "There could be more that we could write to understand `totally` and it's relationship to `cool`, but we'll save that for later. Right now we're going to stick to analyzing unigrams (single words) as just a bag (which actually works really well as a first approximation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I want to start with text that we already understand. So lets pull in Iago and Othello's text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iago_words = [l.strip() for l in open('../data/IAGO_nltk_words.txt').readlines()]\n",
    "othello_words = [l.strip() for l in open('../data/OTHELLO_nltk_words.txt').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remember, we saved the stemmed words and AFINN has full, unstemmed words. In order to find almost any words in AFINN we will need to stem the words in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pull the sentiment for Iago and Othello's dialogue. How many words have a definition here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a small fraction of the words have a sentiment coded in the dictionary. Some of this is due to the number of words carrying sentiment being smaller, while the other part is the mismatch in dictionary source to that of the target data.\n",
    "\n",
    "Still we should examine what we have done so far here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.plot(pull_sentiment(iago_words), label='Iago')\n",
    "plt.plot(pull_sentiment(othello_words), label='Othello')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too noisy, ideally we would want to see a moving average. We can write one ourselves or we can use Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "othello_running = pd.Series(pull_sentiment(othello_words)).rolling(window=20).mean()\n",
    "iago_running = pd.Series(pull_sentiment(iago_words)).rolling(window=20).mean()\n",
    "\n",
    "plt.plot(othello_running, label='Othello')\n",
    "plt.plot(iago_running, label='Iago')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an easier fashion, we could use this to assess the tone of Othello over time. Read in the entire play and plot the sentiment over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are those dips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can begin to 'visualize' what each act is like now through this simple analysis. Even though this sentiment dictionary is *very* mismatched to this dataset, it still works to deliver a coarse analysis/first approximation. One wouldn't publish with this data, but it would be a quick first pass that you could use to justify further effort in developing or purchasing a sentiment dictionary that was actually appropriate for the source text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matching the dictionary to its purpose\n",
    "\n",
    "Since the AFINN dataset is actually for 'microblogs', we will now switch to the nltk twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_samples.strings('tweets.20150430-223406.json')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this corpus is composed of completely non-confrontational tweets surrounding the Brexit vote. Using the built-in tools we can pull these tweets out. To start with we will actually use the positive and negative tweets to test how well our dictionary matches the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negtweets = [x for x in twitter_samples.tokenized('negative_tweets.json')]\n",
    "postweets = [x for x in twitter_samples.tokenized('positive_tweets.json')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And  now we can go through and evaluate each of these tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a clear separation in the sum of tone used so long as we discard samples where no sentiment was found for any word there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, NLTK has tools built in to help with sentiment detection. One of the biggest questions is always, \"how do I handle negation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.util import mark_negation\n",
    "\n",
    "sentence = \"I didn't like this movie . It was bad\".split()\n",
    "mark_negation(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the other, would of course be a full blown sentiment analyzer. (Yes, it could do it all along)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import vader\n",
    "\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(\"I didn't like this movie . It was bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that this is giving us the score for an entire sentence/passage though (not on a per word basis). However, it gives a compound score for everything.\n",
    "\n",
    "Let's run through the twitter example again with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([analyzer.polarity_scores(' '.join(x))['compound'] for x in negtweets], bins=25);\n",
    "plt.hist([analyzer.polarity_scores(' '.join(x))['compound'] for x in postweets], bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
