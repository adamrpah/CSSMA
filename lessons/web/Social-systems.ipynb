{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social systems over time\n",
    "\n",
    "Today we are going to examine a social network and how it changes over time. As a dataset we will use the Enron e-mail corpus, which has been analyzed in a number of academic papers. For ease of use, we will be using the Enron dataset that is packaged through [Kaggle Datasets](https://www.kaggle.com/wcukierski/enron-email-dataset). \n",
    "\n",
    "This file is a csv with only two columns, `file` and `message`.  The `file` field is the username of the Outlook mailbox and `message` has a single e-mail message.\n",
    "\n",
    "This file is 1.3 GB so the `pandas` package is not a good way to process this file unless you are on a well spec'ed machine. \n",
    "\n",
    "Instead you should use the `csv` package to parse this file and reduce it to a dataset that we can hold in memory and build networks from.\n",
    "\n",
    "This parsing code does **not** need to be perfect, we just want to get going. We will evaluate our data losses post-parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe, let's evaluate our losses. How should we do that easily?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With my quick and dirty approach I lost approximately 4k records (so one percent). This is a pretty acceptable loss for our exercise.\n",
    "\n",
    "Since this class is about preparation for independent research, we will not jump straight to our analysis topic. \n",
    "\n",
    "Good research is about building an understanding of the dataset. One of the best ways to do that is to understand the degree of individuals.\n",
    "\n",
    "An unweighted, undirected network should be sufficient to gain an intuition of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a baseline for the entire system, now we can start making comparisons at a systems level.\n",
    "\n",
    "Let's start with just restricting and comparing the yearly amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine the change in an individual user's degree over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also statistically test to see if these distributions are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.ks_2samp(diff2000, diff2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A technosocial system, such as e-mail during a period like 2000-2002 is likely to see a dramatic per-user change year over year (as the technology is on a dramatic increase in the utilization across the firm).\n",
    "\n",
    "This is decidedly different from a system that has reached mass adoption. \n",
    "\n",
    "-> How many friends did you add on Facebook in 2017? In 2012? Likely very different.\n",
    "\n",
    "**But has the network itself changed?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TE** What is your explanation for this observed behavior?\n",
    "\n",
    "Now examine month to month behavior in 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So how do we study a social network over time? \n",
    "\n",
    "The major concern with studying a network over a time period, is that the behavior that you observe is an artifact of the time window that has been chosen. \n",
    "\n",
    "**Why?** Let's think through this. Assume that each agent $A$ has a behavioral pattern that is drawn from some distribution $B$. On any given day, the agent $A$ draws an action from distribution $B$ and after some period, say 3 weeks, the user will have, effectively, drawn a full set of behaviors from distribution $B$.\n",
    "\n",
    "If you were to sample the network at 1-week intervals, then it is impossible to have observed that user's complete behavior pattern. Since you do not know what, if anything, influenced the draws from $B$ then given one week's worth of data you will not be able to properly estimate the distribution.\n",
    "\n",
    "Since we are interested in properly characterizing agent behavior, thie means that your time window should be significantly larger (how much larger, we'll get to that) than the typical time-scale of the phenomena under study. \n",
    "\n",
    "## 1. Your question imposes time and the change in behavior is the quantity of interest\n",
    "\n",
    "If you ask a question, such as \"How did the facebook graph change 6 months after X? one year after X?\" then you find yourself in a relatively easy analytical situation since the question itself has imposed the timescale. \n",
    "\n",
    "Major issue - you can answer your question, but given how arbitrary the choice is the analysis will lack generalizability to other contexts. In this example, it is unclear why the change in the facebook network will be the same as the Twitter network. \n",
    "\n",
    "## 2. Some event has occurred that marks the shift in time (i.e. natural experiment like)\n",
    "\n",
    "There is an exogenous shock to the system, you then study the network pre- and post- the event. Without multiple event occurrences, then generalizability will also be greatly hampered (although you at least have a reason as to why the time was split as such).\n",
    "\n",
    "## 3. You use time markers that produce stable networks \n",
    "\n",
    "Since we are interested in properly characterizing agent behavior, thie means that your time window should be significantly larger (how much larger, we'll get to that) than the typical time-scale of the phenomena under study. \n",
    "\n",
    "Your options: *a priori* knowledge about the behavioral process or data-driven estimation of the behavioral process. \n",
    "\n",
    "## Hasn't someone already studied/developed a method to identify the characteristic time scale of a network\n",
    "\n",
    "This is a general problem that researchers encounter. However, there is a large heterogeneity in network types and associated statistical characterization for methods to identify a characteristic time scale is not robust enough for me to recommend its direct usage and implementation without a significant amount of additional verification and characterization of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pictorial representation\n",
    "\n",
    "### Step 1. Calculate network quantity you want to control for and plot in distinct time unites\n",
    "\n",
    "<img src='../images/networktime/step1.jpeg' width='500'></img>\n",
    "\n",
    "### Step 2. Segment the dataset into time periods that have values drawn from the same distribution\n",
    "\n",
    "<img src='../images/networktime/step2.jpeg' width = '500'></img>\n",
    "\n",
    "### Step 3. Select a segment with behavior that is drawn from the same statistical distribution\n",
    "\n",
    "<img src='../images/networktime/step3.jpeg' width = '500'></img>\n",
    "\n",
    "### Step 4. Confirm that data points are drawn from the same distribution if your methodology did not\n",
    "\n",
    "<img src='../images/networktime/step4.jpeg' width='500'></img>\n",
    "\n",
    "### Step 5. Select one period and split into two (or more) periods to compare your hypotheses against.\n",
    "\n",
    "<img src='../images/networktime/step5.jpeg' width='180'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "J. Saramaki and E. Moro. From seconds to months: multi-scale dynamics of mobile telephone calls. https://arxiv.org/pdf/1504.01479.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
