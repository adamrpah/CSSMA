{"cells": [{"cell_type": "code", "metadata": {"collapsed": false}, "source": ["from IPython.core.display import HTML\n", "def css_styling():\n", "    styles = open(\"../Data/www/styles/custom.css\", \"r\").read()\n", "    return HTML(styles)\n", "css_styling()"], "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["<style>\n", "    @font-face {\n", "        font-family: \"Computer Modern\";\n", "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n", "    }\n", "    @font-face {\n", "        font-family: \"Computer Modern\";\n", "        font-weight: bold;\n", "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n", "    }\n", "    @font-face {\n", "        font-family: \"Computer Modern\";\n", "        font-style: oblique;\n", "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n", "    }\n", "    @font-face {\n", "        font-family: \"Computer Modern\";\n", "        font-weight: bold;\n", "        font-style: oblique;\n", "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n", "    }\n", "    h1 {\n", "        font-family: Helvetica, serif;\n", "    }\n", "    h4{\n", "        margin-top:12px;\n", "        margin-bottom: 3px;\n", "       }\n", "    div.text_cell_render{\n", "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n", "        line-height: 145%;\n", "        font-size: 130%;\n", "        margin-left:auto;\n", "        margin-right:auto;\n", "    }\n", "    .CodeMirror{\n", "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n", "    }\n", "    .text_cell_render h5 {\n", "        font-weight: 300;\n", "        font-size: 22pt;\n", "        color: #4057A1;\n", "        font-style: italic;\n", "        margin-bottom: .5em;\n", "        margin-top: 0.5em;\n", "        display: block;\n", "    }\n", "    \n", "    .warning{\n", "        color: rgb( 240, 20, 20 )\n", "        }  \n", "</style>\n", "<script>\n", "    MathJax.Hub.Config({\n", "                        TeX: {\n", "                           extensions: [\"AMSmath.js\"]\n", "                           },\n", "                tex2jax: {\n", "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n", "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n", "                },\n", "                displayAlign: 'center', // Change this to 'center' to center equations.\n", "                \"HTML-CSS\": {\n", "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n", "                }\n", "        });\n", "</script>\n"]}, "execution_count": 1}], "execution_count": 1}, {"cell_type": "code", "metadata": {"collapsed": false, "scrolled": true}, "source": ["import requests\n", "import json\n", "from IPython.display import HTML\n", "import bs4\n", "from IPython.display import display, Image"], "outputs": [], "execution_count": 2}, {"cell_type": "markdown", "metadata": {}, "source": ["# Synopsis\n", "\n", "In this unit we will cover:\n", "\n", "* The structure of Web pages\n", "* What is HTML/CSS\n", "* How to extract information from HTML pages\n", "* Techniques for navigating and scraping web pages\n", "\n", "\n", "# Interacting with the Web (Part II)\n", "\n", "In the previous units, we learned how to retrieve data from Web sources using APIs. But what if the organization hosting the data does not have the forethought or resources to create an API (or if they do not want to share their data)?  Then, we have to **crawl** their website and **scrape** their data.\n", "\n", "To do this, we will be using our dependable `requests` library.  However, we will need to call upon a few other resources.  In particular, we will need to understand the code in which webpages are written.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["+++"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Detour: A (very brief) intro to HTML\n", "\n", "HTML is a markup language for describing web documents. It stands for **H**yper **T**ext **M**arkup **L**anguage. HTML, together with CSS (**C**ascading **S**tyle **S**heets for _styling_ web documents) and Javascript (for _animating_ web documents), it is the language that is used to construct web pages.\n", "\n", "HTML documents are built using a series of HTML _tags_. Each tag describes a different type of content. Web pages are built by putting together different tags.\n", "\n", "This is the general HTML tag structure:\n", "\n", "```html\n", "<tagname tag_attribute1=\"attribute1value1 attribute1value2\" tag_attribute2=\"attribute2value1\">tag contents</tagname>\n", "```\n", "* Tags (usually) have both a start (or opening) tag, <tagname> and an end (or closing) tag, </tagname>\n", "* Tags can also have attributes which are declared _inside_ the opening tag.\n", "* The actual tag _content_ goes inbetween the opening and closing tags."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tags can be contained (nested) inside other tags, which defines relationships between them:\n", "\n", "```html\n", "<parent>\n", "  <brother></brother>\n", "  <sister>\n", "    <grandson></grandson>\n", "  </sister>\n", "</parent>\n", "```\n", "\n", "* `<parent>` is the _parent_ tag of `<brother>` and `<sister>`\n", "* `<brother>` and `<sister>` are the _children_ or _direct descendant_ tags of `<parent>`\n", "* `<brother>`, `<sister>`, and `<grandson>` are the _descendant_ tags of `<parent>`\n", "* `<brother>` and `<sister>` are _sibling_ tags"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here's a very simple web document:\n", "\n", "```html\n", "<!DOCTYPE html>\n", "<html>\n", "  <head>\n", "    <title>Page Title</title> \n", "  </head>\n", "\n", "  <body>\n", "    <h1>My First Heading</h1>\n", "    <p>My first paragraph.</p>\n", "  </body>\n", "</html> \n", "```\n", "\n", "Here, `<h1>` and `<p>` are sibling tags, `<body>` is their parent tag, and all three are descendent tags of `<html>`\n", "\n", "When you access any URL, your browser (Chrome, Firefox, Safari, IE, etc.) is actually reading a document such as this one and using the tags within the document to decide how to render the page for you.\n", "\n", "Jupyter is able to render a (python) string of HTML code as real HTML in the notebook itself!"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["#from IPython.display import HTML\n", "\n", "first_html = \"\"\"\n", "<!DOCTYPE html>\n", "<html>\n", "  <head>\n", "    <title>Page Title</title>\n", "  </head>\n", "  \n", "  <body>\n", "    <h1>My First Heading</h1>\n", "    <p>My first paragraph.</p>\n", "  </body>\n", "\n", "</html> \n", "\"\"\"\n", "\n", "HTML(first_html)"], "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<!DOCTYPE html>\n", "<html>\n", "  <head>\n", "    <title>Page Title</title>\n", "  </head>\n", "  \n", "  <body>\n", "    <h1>My First Heading</h1>\n", "    <p>My first paragraph.</p>\n", "  </body>\n", "\n", "</html> \n"]}, "execution_count": 92}], "execution_count": 92}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Let's look at what the different tags mean:\n", "\n", "```html\n", "<!-- This is how you write a comment in HTML. Comments will not show up in the browser -->\n", "\n", "<!-- This line simply identifies the document type to be HTML-->\n", "<!DOCTYPE html>\n", "<!-- Content between <html> and </html> tags define everything about the document-->\n", "<html>\n", "  <!-- Tags inside the <head> are not rendered but provide general information about the document -->\n", "  <head>\n", "    <!-- Like the <title> tag which provides a title that appears in the browser's title and tab bars -->\n", "    <title>Page Title</title>\n", "  </head>\n", "  \n", "  <!-- Anything inside the <body> tags describes visible page content -->\n", "  <body>\n", "    <!-- The <h1> defines a header. The number defines the size of the header. -->\n", "    <!-- There are 6 levels of headers: <h1> to <h6> -->\n", "    <!-- The higher the number, the lower the font used to display it. -->\n", "    <h1>My First Heading</h1>\n", "    <!-- The <p> represents a paragraph.-->\n", "    <p>My first paragraph.</p>\n", "  </body>\n", "</html>\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Different levels of headers**\n", "\n", "```html\n", "<h1>This is heading 1</h1>\n", "<h2>This is heading 2</h2>\n", "<h3>This is heading 3</h3>\n", "<h4>This is heading 4</h4>\n", "<h5>This is heading 5</h5>\n", "<h6>This is heading 6</h6> \n", "```\n", "\n", "**Links**\n", "```html\n", "<a href=\"http://www.website.com\">Click to go to website.com</a>\n", "```\n", "\n", "**Images**\n", "```html\n", "<!-- Notice that the image tag has no closing tag and no content outside the opening tag -->\n", "<img src=\"smiley.gif\">\n", "```\n", "\n", "**Lists**\n", "```html\n", "<!-- Unordered (bulleted) list -->\n", "<ul>\n", "  <li>One Element</li>\n", "  <li>Another Element</li>\n", "</ul>\n", "\n", "<!-- Ordered (numbered) list -->\n", "<ol>\n", "  <li>First Ordered Element</li>\n", "  <li>Second Ordered Element</li>\n", "</ol>\n", "```\n", "\n", "**Tables**\n", "```html\n", "<table>\n", "  <!-- An HTML table is defined as a series of rows (<tr>) -->\n", "  <!-- The individual cell (<td>) contents are nested inside rows -->\n", "  \n", "  <!-- The <tr> tag is optional and is the parent of column headers (<th>) -->\n", "  <tr>\n", "    <th>First Header</th>\n", "    <th>Second Header</th>\n", "  </tr>\n", "  <tr>\n", "    <td>Row 2, Col 1</td>\n", "    <td>Row 2, Col 2</td>\n", "  </tr>\n", "  <tr>\n", "    <td>Row 3, Col 1</td>\n", "    <td>Row 3, Col 2</td>\n", "  </tr>\n", "</table>\n", "```"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["more_tags = \"\"\"\n", "<html>\n", "<head>\n", "  <title>More HTML Tags</title>\n", "</head>\n", "<body>\n", "  <h1>This is heading 1</h1>\n", "  <h2>This is heading 2</h2>\n", "  <h3>This is heading 3</h3>\n", "  <h4>This is heading 4</h4>\n", "  <h5>This is heading 5</h5>\n", "  <h6>This is heading 6</h6>\n", "\n", "  <br>\n", "  \n", "  <a href=\"http://www.website.com\">Click to go to website.com</a>\n", "\n", "  <p><img src=\"../Data/www/images/smiley.png\" alt=\"smiley face\"></p>\n", "\n", "  <ul>\n", "    <li>One Element</li>\n", "    <li>Another Element</li>\n", "  </ul>\n", "\n", "  <ol>\n", "    <li>First Ordered Element</li>\n", "    <li>Second Ordered Element</li>\n", "  </ol>\n", "\n", "  <table>\n", "    <!-- An HTML table is defined as a series of rows (<tr>) -->\n", "    <!-- The individual cell (<td>) contents are nested inside rows -->\n", "    <tr>\n", "      <!-- The <tr> tag defines a column headers -->\n", "      <th>First Header</th>\n", "      <th>Second Header</th>\n", "    </tr>\n", "    <tr>\n", "      <td>Row 2, Col 1</td>\n", "      <td>Row 2, Col 2</td>\n", "    </tr>\n", "    <tr>\n", "    <td>Row 3, Col 1</td>\n", "    <td>Row 3, Col 2</td>\n", "  </tr>\n", "  </table>\n", "</body>\n", "</html>\n", "\"\"\"\n", "\n", "HTML(more_tags)"], "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<html>\n", "<head>\n", "  <title>More HTML Tags</title>\n", "</head>\n", "<body>\n", "  <h1>This is heading 1</h1>\n", "  <h2>This is heading 2</h2>\n", "  <h3>This is heading 3</h3>\n", "  <h4>This is heading 4</h4>\n", "  <h5>This is heading 5</h5>\n", "  <h6>This is heading 6</h6>\n", "\n", "  <br>\n", "  \n", "  <a href=\"http://www.website.com\">Click to go to website.com</a>\n", "\n", "  <p><img src=\"../Data/www/images/smiley.png\" alt=\"smiley face\"></p>\n", "\n", "  <ul>\n", "    <li>One Element</li>\n", "    <li>Another Element</li>\n", "  </ul>\n", "\n", "  <ol>\n", "    <li>First Ordered Element</li>\n", "    <li>Second Ordered Element</li>\n", "  </ol>\n", "\n", "  <table>\n", "    <!-- An HTML table is defined as a series of rows (<tr>) -->\n", "    <!-- The individual cell (<td>) contents are nested inside rows -->\n", "    <tr>\n", "      <!-- The <tr> tag defines a column headers -->\n", "      <th>First Header</th>\n", "      <th>Second Header</th>\n", "    </tr>\n", "    <tr>\n", "      <td>Row 2, Col 1</td>\n", "      <td>Row 2, Col 2</td>\n", "    </tr>\n", "    <tr>\n", "    <td>Row 3, Col 1</td>\n", "    <td>Row 3, Col 2</td>\n", "  </tr>\n", "  </table>\n", "</body>\n", "</html>\n"]}, "execution_count": 93}], "execution_count": 93}, {"cell_type": "markdown", "metadata": {}, "source": ["+++"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you want to know more about HTML, I recommend the excellent w3schools website: http://www.w3schools.com/html/html_intro.asp"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "#### Ok, back to web scraping\n", "\n", "Now we are all HTML experts. Great! We're almost ready to start parsing and analyzing a scraped web page. There's just one last item of business we need to discuss before we get started."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Viewing a page's source code\n", "\n", "In order to extract elements of interest from a webpage we need to know where they sit in the webpage's HTML tree.\n", "This means that you need to look at a webpage's HTML source code before you can even start scraping it. Not only that but, during your web scraping you will be switching back and forth between the actual scraping (we'll get there really soon, I promise!) and the webpage's source code.\n", "\n", "How do we view a page's source code then?\n", "\n", "* To view the **full page** source code:\n", "  1. Right-click anywhere on the webpage **that is not a link**\n", "  2. Click \"View Page Source\" (<kbd>CTRL</kbd>+<kbd>U</kbd>) in Firefox or Chrome, or \"Show page source\" (<kbd>&#8997;</kbd>+<kbd>&#8984;</kbd>+<kbd>U</kbd>) in Safari.\n", "    * In order to view the source code in Safari the Develop menu must be enabled first: Preferences > Advanced > Show Develop menu in menu bar\n", "    \n", "* To view the source code zoomed-in on **a single element** (and with better formatting!):\n", "  1. Right-click any element in the webpage.\n", "  2. Click \"Inspect Element\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["##  Beautiful Soup, so rich and green, waiting in a hot tureen!\n", "\n", "(*The Lobster Quadrille*, Alice in Wonderland)\n", "\n", "We made it! We are now ready to start scraping web pages. In order to do so we are going to use [`BeautifulSoup`](http://www.crummy.com/software/BeautifulSoup/bs4/doc/), a powerful python package to parse web pages you already scraped. Normally you would use `requests` (to GET the page) and then `BeautifulSoup` to analyse the web page.\n", "\n", "We will use the wikipedia page for a player from Germany's national football team as an example: https://en.wikipedia.org/wiki/Erik_Durm that has already been downloaded into the `Data/` folder. We are starting with a pre-downloaded HTML page so that there aren't a hundred requests from the same place for the same page at the same server at the same time from (which will frequently result in you getting blocked from accessing that website!)"]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["\n", "# Beautiful Soup version 4.x\n", "#import bs4"], "outputs": [], "execution_count": 94}, {"cell_type": "markdown", "metadata": {}, "source": ["We start by opening up the page and convert it to a `soup` object. Then, we're going to use the `find` method to find the page's `<title>` tag and print it."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["# We specify the encoding of the file here because Windows\n", "# has problems reading some characters in it.\n", "\n", "with open(\"../Data/erik_durm_wiki.html\", \"r\", encoding=\"utf-8\") as wiki_file:\n", "        soup = bs4.BeautifulSoup(wiki_file.read())\n", "        \n", "title = soup.find('title')   #finds the FIRST <title> tag \n", "print(title.text)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Erik Durm - Wikipedia, the free encyclopedia\n"]}, {"output_type": "stream", "name": "stderr", "text": ["/Users/adampah/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n", "\n", "To get rid of this warning, change this:\n", "\n", " BeautifulSoup([your markup])\n", "\n", "to this:\n", "\n", " BeautifulSoup([your markup], \"lxml\")\n", "\n", "  markup_type=markup_type))\n"]}], "execution_count": 95}, {"cell_type": "markdown", "metadata": {}, "source": ["Beautiful Soup converts HTML tags into its own `Tag` objects.`Tag` objects have many useful attributes."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["print(type(title))\n", "print(title.text) # The text gives you the visible part of the tag\n", "print(title.name) # The type of tag"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["<class 'bs4.element.Tag'>\n", "Erik Durm - Wikipedia, the free encyclopedia\n", "title\n"]}], "execution_count": 96}, {"cell_type": "markdown", "metadata": {}, "source": ["If a tag has any html attributes, they can be accessed in a very \"pythonic\" way. That is, they are organized as a dictionary!\n", "\n"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["h1 = soup.find(\"h1\")\n", "\n", "print(h1.attrs)\n", "print(h1[\"class\"])\n", "print(h1[\"id\"])"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["{'id': 'firstHeading', 'lang': 'en', 'class': ['firstHeading']}\n", "['firstHeading']\n", "firstHeading\n"]}], "execution_count": 97}, {"cell_type": "markdown", "metadata": {}, "source": ["Instead of searching for `Tags` one by one, we can also retrieve them all at once.  As an example, let's find all level 2 headers. To this end, we use the `find_all` method."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["headers = soup.find_all('h2')\n", "\n", "print(headers)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["[<h2>Contents</h2>, <h2><span class=\"mw-headline\" id=\"Club_career\">Club career</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=1\" title=\"Edit section: Club career\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>, <h2><span class=\"mw-headline\" id=\"International_career\">International career</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=4\" title=\"Edit section: International career\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>, <h2><span class=\"mw-headline\" id=\"Career_statistics\">Career statistics</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=7\" title=\"Edit section: Career statistics\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>, <h2><span class=\"mw-headline\" id=\"Honours\">Honours</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=10\" title=\"Edit section: Honours\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>, <h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=13\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>, <h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=14\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>, <h2>Navigation menu</h2>]\n"]}], "execution_count": 98}, {"cell_type": "markdown", "metadata": {}, "source": ["Too much information!  In order to get the only the information that we need, we must restrict to the desired attribute."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["for header in headers:\n", "    print(header.text)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Contents\n", "Club career[edit]\n", "International career[edit]\n", "Career statistics[edit]\n", "Honours[edit]\n", "References[edit]\n", "External links[edit]\n", "Navigation menu\n"]}], "execution_count": 99}, {"cell_type": "markdown", "metadata": {}, "source": ["Another `Tag` that that is useful and that demonstrate some of the other useful attributes is the one for webpages that our page points to:"]}, {"cell_type": "code", "metadata": {"collapsed": false, "scrolled": false}, "source": ["links = soup.find_all('a')\n", "\n", "for link in links[:10]:  # Showing just the first 10 links for brevity\n", "    # href represents the target of the link\n", "    # Where the link actually goes to!\n", "    print('-----', link.text)\n", "    print(link.get('href'))\n", "    "], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["----- \n", "None\n", "----- navigation\n", "#mw-head\n", "----- search\n", "#p-search\n", "----- \n", "/wiki/File:Erik_Durm_IMG_1748.jpg\n", "----- BVB\n", "/wiki/Borussia_Dortmund\n", "----- [1]\n", "#cite_note-1\n", "----- Pirmasens\n", "/wiki/Pirmasens\n", "----- Left back\n", "/wiki/Defender_(association_football)#Full-back\n", "----- Right back\n", "/wiki/Defender_(association_football)#Full-back\n", "----- Borussia Dortmund\n", "/wiki/Borussia_Dortmund\n"]}], "execution_count": 100}, {"cell_type": "markdown", "metadata": {}, "source": ["### Searching using attribute information\n", "\n", "Some `Tag` elements have attributes associated with them. These includes `id`, `class_`, `href`.  Our search can restrict results to attributes with a specific value or to results where the attribute type is included.\n", "\n", "Note that we must use `class_` instead of `class` to avoid conflicts with Python's built-in keyword. \n", "\n"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["# Retrieve the element with the attribute \"id\" equal to \"Early_career\"\n", "tag = soup.find(id=\"Early_career\")\n", "print(tag)\n", "print(tag.text)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["<span class=\"mw-headline\" id=\"Early_career\">Early career</span>\n", "Early career\n"]}], "execution_count": 101}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["# Retrieve all elements with an href attribute\n", "all_links = soup.find_all(href=True)\n", "print(len(all_links))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["373\n"]}], "execution_count": 102}, {"cell_type": "code", "metadata": {"collapsed": false, "scrolled": false}, "source": ["# Retrieve inline citations -- they are <sup> elements with the class \"reference\"\n", "soup.find_all(\"sup\", class_=\"reference\")[5:15]"], "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["[<sup class=\"reference\" id=\"cite_ref-6\"><a href=\"#cite_note-6\"><span>[</span>6<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-7\"><a href=\"#cite_note-7\"><span>[</span>7<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-8\"><a href=\"#cite_note-8\"><span>[</span>8<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-9\"><a href=\"#cite_note-9\"><span>[</span>9<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-10\"><a href=\"#cite_note-10\"><span>[</span>10<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-11\"><a href=\"#cite_note-11\"><span>[</span>11<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\"><span>[</span>12<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-2014_German_Super_Cup_13-0\"><a href=\"#cite_note-2014_German_Super_Cup-13\"><span>[</span>13<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-14\"><a href=\"#cite_note-14\"><span>[</span>14<span>]</span></a></sup>,\n", " <sup class=\"reference\" id=\"cite_ref-15\"><a href=\"#cite_note-15\"><span>[</span>15<span>]</span></a></sup>]"]}, "execution_count": 103}], "execution_count": 103}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["# Retrieve all tags with class=mw-headline and an id attribute (regardless of value)\n", "soup.find_all(attrs={\"class\": \"mw-headline\", \"id\": True})"], "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["[<span class=\"mw-headline\" id=\"Club_career\">Club career</span>,\n", " <span class=\"mw-headline\" id=\"Early_career\">Early career</span>,\n", " <span class=\"mw-headline\" id=\"Borussia_Dortmund\">Borussia Dortmund</span>,\n", " <span class=\"mw-headline\" id=\"International_career\">International career</span>,\n", " <span class=\"mw-headline\" id=\"Youth\">Youth</span>,\n", " <span class=\"mw-headline\" id=\"Senior\">Senior</span>,\n", " <span class=\"mw-headline\" id=\"Career_statistics\">Career statistics</span>,\n", " <span class=\"mw-headline\" id=\"Club\">Club</span>,\n", " <span class=\"mw-headline\" id=\"International\">International</span>,\n", " <span class=\"mw-headline\" id=\"Honours\">Honours</span>,\n", " <span class=\"mw-headline\" id=\"Club_2\">Club</span>,\n", " <span class=\"mw-headline\" id=\"International_2\">International</span>,\n", " <span class=\"mw-headline\" id=\"References\">References</span>,\n", " <span class=\"mw-headline\" id=\"External_links\">External links</span>]"]}, "execution_count": 104}], "execution_count": 104}, {"cell_type": "markdown", "metadata": {}, "source": ["#### A little more HTML\n", "\n", "`class` and `id` are special HTML attributes that allow for a rich connection between HTML and CSS and Javascript. Feel free to google the subject. We won't go into the details here. Just know that:\n", "\n", "* The `id` attribute is used to uniquely identify a tag. This means that all `id` attributes should have different values in a webpage.\n", "\n", "* The `class` attribute is used to identify tags which share certain properties. A tag can have more than one `class` value:\n", "```html\n", "   <!-- Separate extra classes by a space -->\n", "   <tag class=\"first_class second_class\">...</tag>\n", "```\n", "\n", "In the above example, notice that all reference elements (`<sup>` tags) have the same `class` value but different `id` values."]}, {"cell_type": "markdown", "metadata": {}, "source": ["+++"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Navigating the HTML tree with BeautifulSoup\n", "\n", "\n", "Besides being able to search elements anywhere on the whole html tree, beautiful soup also allows you to navigate the tree in any direction.\n", "\n", "Let's try to get at the first paragraph (`<p>`) in the `Club career` section starting from the section's title tag.\n", "\n", "Here's the relevant HTML snippet:\n", "\n", "```html\n", "    <h2>\n", "      <span class=\"mw-headline\" id=\"Club_career\">Club career</span>\n", "      <span class=\"mw-editsection\">\n", "        <span class=\"mw-editsection-bracket\">[</span>\n", "        <a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=1\" title=\"Edit section: Club career\">edit</a>\n", "        <span class=\"mw-editsection-bracket\">]</span>\n", "      </span>\n", "    </h2>\n", "    <h3>\n", "      <span class=\"mw-headline\" id=\"Early_career\">Early career</span>\n", "      <span class=\"mw-editsection\">\n", "        <span class=\"mw-editsection-bracket\">[</span>\n", "        <a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=2\" title=\"Edit section: Early career\">edit</a>\n", "        <span class=\"mw-editsection-bracket\">]</span>\n", "      </span>\n", "    </h3>\n", "    <p>Durm began his club career in 1998 at the academy of SG Rieschweiler....</p>\n", "```\n", "\n", "We can see that that section of text is *under* the \"Club career\" title: "]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["section_headline = soup.find(id=\"Club_career\")\n", "print(section_headline)\n", "print(section_headline.text)\n", "section_headline.contents"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["<span class=\"mw-headline\" id=\"Club_career\">Club career</span>\n", "Club career\n"]}, {"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["['Club career']"]}, "execution_count": 105}], "execution_count": 105}, {"cell_type": "markdown", "metadata": {}, "source": ["The `contents` attribute lets us access everything that is inside a given tag. In this case we find only the visible text of the tag.\n", "\n", "Looking at the webpage snippet, we see that the tag `<p>` is at the same level as the tags `<h2>` and `<h3>`.  Hence, we need to navigate up one level (to the `<h2>` tag), then navigate to its second sibling (first `<h3>` then `<p>`)."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["parent_h2 = section_headline.parent  # Up one level\n", "print( parent_h2.name == \"h2\" )      # Is it the <h2> tag?\n", "print()\n", "print(parent_h2.contents)            "], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["True\n", "\n", "[<span class=\"mw-headline\" id=\"Club_career\">Club career</span>, <span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=1\" title=\"Edit section: Club career\">edit</a><span class=\"mw-editsection-bracket\">]</span></span>]\n"]}], "execution_count": 106}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["one_step = parent_h2.next_sibling\n", "print(one_step.name)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["None\n"]}], "execution_count": 107}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["two_steps = one_step.next_sibling\n", "print(two_steps.name)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["h3\n"]}], "execution_count": 108}, {"cell_type": "markdown", "metadata": {}, "source": ["We are only at the `<h3>` tag even though we moved past two siblings.  The reason is that some of the siblings in the soup are not actual HTML elements. Some could simply be empty lines."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["three_steps = two_steps.next_sibling\n", "print(three_steps.name)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["None\n"]}], "execution_count": 109}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["four_steps = three_steps.next_sibling\n", "print(four_steps.name)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["p\n"]}], "execution_count": 110}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["print(four_steps.contents)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["['Durm began his club career in 1998 at the academy of SG Rieschweiler, before joining the academy of ', <a href=\"/wiki/1._FC_Saarbr%C3%BCcken\" title=\"1. FC Saarbr\u00fccken\">1. FC Saarbr\u00fccken</a>, ' in 2008 where he became youth league top scorer of the 2009\u20132010 season with 13 goals.', <sup class=\"reference\" id=\"cite_ref-pfaelzischer-merkur.de_2-0\"><a href=\"#cite_note-pfaelzischer-merkur.de-2\"><span>[</span>2<span>]</span></a></sup>, ' In July 2010, Durm was enrolled at the academy of ', <a href=\"/wiki/1._FSV_Mainz_05\" title=\"1. FSV Mainz 05\">1. FSV Mainz 05</a>, ' and won the 2010\u201311 Youth Federation Cup in Germany and Durm debuted and played his only game of the 2010\u201311 season for the second team of 1. FSV Mainz 05 on 4 December 2010 against ', <a href=\"/wiki/SV_Elversberg\" title=\"SV Elversberg\">SV Elversberg</a>, ' in the German ', <a href=\"/wiki/Regionalliga\" title=\"Regionalliga\">Regionalliga</a>, '.', <sup class=\"reference\" id=\"cite_ref-3\"><a href=\"#cite_note-3\"><span>[</span>3<span>]</span></a></sup>]\n"]}], "execution_count": 111}, {"cell_type": "markdown", "metadata": {}, "source": ["Ok. Now we are where we wanted to be. We have the text corresponding to the `<p>` tag.  This is something we must always be mindful about. Web scraping can, and very frequently will be, messy and will involve trial-and-error...\n", "\n", "We can the contents of our desired element is a list.  Let's obtain the number of elements and check what they contain."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["print(len(four_steps.contents))\n", "print(four_steps.contents[1])\n", "print(four_steps.contents[5])"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["12\n", "<a href=\"/wiki/1._FC_Saarbr%C3%BCcken\" title=\"1. FC Saarbr\u00fccken\">1. FC Saarbr\u00fccken</a>\n", "<a href=\"/wiki/1._FSV_Mainz_05\" title=\"1. FSV Mainz 05\">1. FSV Mainz 05</a>\n"]}], "execution_count": 112}, {"cell_type": "markdown", "metadata": {}, "source": ["In order to find the desired tag, we choose a easily identifiable starting point -- `id` is great because its value must be unique -- and then navigate the HTML tree to the correct parent and transversed siblings until we got to the right one. \n", "\n", "Clearly, this is not a very elegant solution. If there were hundreds of siblings that would have been very cumbersome. Fortunately, there is an alternative way:"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["parent_h2.find_next_sibling(\"p\")"], "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["<p>Durm began his club career in 1998 at the academy of SG Rieschweiler, before joining the academy of <a href=\"/wiki/1._FC_Saarbr%C3%BCcken\" title=\"1. FC Saarbr\u00fccken\">1. FC Saarbr\u00fccken</a> in 2008 where he became youth league top scorer of the 2009\u20132010 season with 13 goals.<sup class=\"reference\" id=\"cite_ref-pfaelzischer-merkur.de_2-0\"><a href=\"#cite_note-pfaelzischer-merkur.de-2\"><span>[</span>2<span>]</span></a></sup> In July 2010, Durm was enrolled at the academy of <a href=\"/wiki/1._FSV_Mainz_05\" title=\"1. FSV Mainz 05\">1. FSV Mainz 05</a> and won the 2010\u201311 Youth Federation Cup in Germany and Durm debuted and played his only game of the 2010\u201311 season for the second team of 1. FSV Mainz 05 on 4 December 2010 against <a href=\"/wiki/SV_Elversberg\" title=\"SV Elversberg\">SV Elversberg</a> in the German <a href=\"/wiki/Regionalliga\" title=\"Regionalliga\">Regionalliga</a>.<sup class=\"reference\" id=\"cite_ref-3\"><a href=\"#cite_note-3\"><span>[</span>3<span>]</span></a></sup></p>"]}, "execution_count": 113}], "execution_count": 113}, {"cell_type": "markdown", "metadata": {}, "source": ["Much nicer!\n", "\n", "Besides the `find_next_sibling` method, there are also `find_previous_sibling`, `find_next_children`, `find_previous_children`, and many others.\n", "\n", "The [Beautiful Soup documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) has a comprehensive list of all these methods. There is no need to memorize all of them. It's more important to realize that, as with any programming language, there is more than one way to get any element of the html tree. The trick is to *pick a good starting point* from where to start the scraping.\n", "\n", "## Scraping images from a webpage\n", "\n", "You can also use Beautiful Soup to get the source of an image from a webpage. It works just the same as for text."]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["# Some modules that will allows us to display images and other media in the notebook itself\n", "from IPython.display import display, Image"], "outputs": [], "execution_count": 114}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["for image in soup.find_all('img'):\n", "    print(image)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["<img src=\"www/images/Erik_Durm_IMG_1748.jpg\"/>\n", "<img src=\"www/images/Erik_Durm20140714_0009.jpg\"/>\n", "<img alt=\"Germany\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"1000\" height=\"30\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/b/ba/Flag_of_Germany.svg/50px-Flag_of_Germany.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/b/ba/Flag_of_Germany.svg/75px-Flag_of_Germany.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/b/ba/Flag_of_Germany.svg/100px-Flag_of_Germany.svg.png 2x\" width=\"50\"/>\n", "<img alt=\"\" height=\"1\" src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" style=\"border: none; position: absolute;\" title=\"\" width=\"1\"/>\n", "<img alt=\"Wikimedia Foundation\" height=\"31\" src=\"/static/images/wikimedia-button.png\" srcset=\"/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x\" width=\"88\"/>\n", "<img alt=\"Powered by MediaWiki\" height=\"31\" src=\"https://en.wikipedia.org/static/1.26wmf19/resources/assets/poweredby_mediawiki_88x31.png\" srcset=\"https://en.wikipedia.org/static/1.26wmf19/resources/assets/poweredby_mediawiki_132x47.png 1.5x, https://en.wikipedia.org/static/1.26wmf19/resources/assets/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/>\n"]}], "execution_count": 115}, {"cell_type": "markdown", "metadata": {}, "source": ["We can pinpoint a specific image and get its attributes"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["images = soup.find_all('img')\n", "img0 = images[0]\n", "print(img0.attrs)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["{'src': 'www/images/Erik_Durm_IMG_1748.jpg'}\n"]}], "execution_count": 116}, {"cell_type": "markdown", "metadata": {}, "source": ["Then we can display the image using its `src` attribute"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["display(Image(url='../Data/' + img0['src']))\n", "\n", "display(Image(url='../Data/' + images[1]['src']))\n"], "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.Image object>"], "text/html": ["<img src=\"../Data/www/images/Erik_Durm_IMG_1748.jpg\"/>"]}}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.Image object>"], "text/html": ["<img src=\"../Data/www/images/Erik_Durm20140714_0009.jpg\"/>"]}}], "execution_count": 117}, {"cell_type": "markdown", "metadata": {}, "source": ["## Exercise: Scraping results from your Personality profile\n", "\n", "For this exercise you will use your results from the personality quiz at [HEXACO](http://hexaco.org/hexaco-online). You did take the quiz right? :)\n", "\n", "Save the page with the quiz results to: `<path to the bootcamp directory>/Data/my_hexaco.html`"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["with open(\"../Data/my_hexaco.html\", \"r\", encoding=\"utf-8\") as hexaco_file:\n", "        soup = bs4.BeautifulSoup(hexaco_file.read())"], "outputs": [{"output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-118-6b6e89995f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/my_hexaco.html\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhexaco_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhexaco_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/my_hexaco.html'"], "evalue": "[Errno 2] No such file or directory: '../Data/my_hexaco.html'", "ename": "FileNotFoundError"}], "execution_count": 118}, {"cell_type": "markdown", "metadata": {}, "source": ["1 - Find the `<table>` element, that contains your results."]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["table = soup.find() # your search terms inside the `find` method"], "outputs": [], "execution_count": 119}, {"cell_type": "markdown", "metadata": {}, "source": ["2 -  Find all the scale names using the `table` variable from above"]}, {"cell_type": "code", "metadata": {"collapsed": false, "scrolled": false}, "source": ["# Find all table rows, skipping the first two which don't matter\n", "for tag in table.find_all(\"tr\")[2:]:\n", "    cells = tag.find_all(\"td\")\n", "    \n", "    # Your code here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["3: Now get both the scale names and your own scores associated with each scale"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["# Find all table rows, skipping the first two which don't matter\n", "for tag in table.find_all(\"tr\")[2:]:\n", "    cells = tag.find_all(\"td\")\n", "\n", "    # Your code here"], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"language": "python", "name": "Python [Root]", "display_name": "Python [Root]"}, "anaconda-cloud": {}, "language_info": {"mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.5.1", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 0, "nbformat": 4}
