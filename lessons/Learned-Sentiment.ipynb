{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learning Sentiment\n",
    "\n",
    "Someone else's learned sentiment may note be appropriate for your research. This is a common enough issue when you begin to work in narrow niches (i.e. not what's happening on twitter). \n",
    "\n",
    "**How do you go about this?**\n",
    "\n",
    "The basic workflow is relatively simple.\n",
    "\n",
    "1. Cut up your text into characteristic chunks that will provide enough context for another reader. \n",
    "2. Pull out individual adjectives (and possibly adverbs depending on the writing style) from those chunks.\n",
    "3. Show the individual adjective and its corresponding text to another party, ask them to rate it on a positive to negative scale (generally -5 to 5). \n",
    "\n",
    "A relatively simple process given what we have learned so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "The harder part is understanding how to scale. \n",
    "\n",
    "In theory, the concept is simple - get other people to tell you if a word is positive or negative. The difficult part is figuring out how to access such an audience that will also accept the remuneration you are able to provide.\n",
    "\n",
    "Crowdsourcing is generally viewed as the answer to constructing a `training` dataset such as this. There a number of such platforms, but the oldest/most oft used is still Amazon's Mechanical Turk. Given that we will work through how to use this service programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The process of getting set up\n",
    "\n",
    "Having an account with Amazon where you can buy shampoo and beef jerky is insufficient to use Mechanical Turk. MT resides (more or less) as a part of its enterprise services (which are labelled AWS-Amazon Web Services). To be able to be a requester on MT you must:\n",
    "\n",
    "1. Sign up for an AWS account (aws.amazon.com)\n",
    "2. Sign up for an MTurk requester account (requester.mturk.com)\n",
    "3. Link Your MTurk account to your aws account (https://requester.mturk.com/developer)\n",
    "4. Sign up for MTurk Sandbox, which is where you can test your forms without paying actual people (requestersandbox.mturk.com) an dlink your sandbox to the aws account (requestersandbox.mturk.com/developer)\n",
    "5. Set up the IAM (Identity and Access Management) User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and basic AWS Access\n",
    "\n",
    "Fortunately, there is a python package to manage access to AWS (boto3). First you will need to install this package with pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.5.22-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 1.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3)\n",
      "  Downloading s3transfer-0.1.12-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 3.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting botocore<1.9.0,>=1.8.36 (from boto3)\n",
      "  Downloading botocore-1.8.36-py2.py3-none-any.whl (4.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.1MB 166kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/adampah/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages (from botocore<1.9.0,>=1.8.36->boto3)\n",
      "Requirement already satisfied: docutils>=0.10 in /Users/adampah/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages (from botocore<1.9.0,>=1.8.36->boto3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adampah/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.9.0,>=1.8.36->boto3)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.5.22 botocore-1.8.36 jmespath-0.9.3 s3transfer-0.1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you will need to configure a credentials file that goes in your user directory (`~/.aws/credentials`) with your IAM account credentials. The `credentials` file should be structured as:\n",
    "\n",
    "<pre>\n",
    "[default]\n",
    "aws_access_key_id = YOUR_KEY\n",
    "aws_secret_access_key = YOUR_SECRET\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set up a configuration file to tell Amazon which region you want your services to be started in (`~/.aws/config`)?\n",
    "\n",
    "<pre>\n",
    "[default]\n",
    "region=us-east-1\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can check your sandbox balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "MTURK_SANDBOX = 'https://mturk-requester-sandbox.us-east-1.amazonaws.com'\n",
    "\n",
    "mturk = boto3.client('mturk', endpoint_url = MTURK_SANDBOX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaiable sandbox balance: 10000.00\n"
     ]
    }
   ],
   "source": [
    "#Should have 10,000 available\n",
    "print(\"Available sandbox balance: {0}\".format(mturk.get_account_balance()['AvailableBalance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you instead want to connect to your actual MTurk account and marketplace, you can just leave out the endpoint url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My real money: 9.90\n"
     ]
    }
   ],
   "source": [
    "real_mturk = boto3.client('mturk')\n",
    "print(\"My real money: {0}\".format(real_mturk.get_account_balance()['AvailableBalance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I don't want to actually pay money yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del real_mturk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminology\n",
    "\n",
    "**Worker**: Anyone on the other side of the MTurk marketplace. Workers can view all open assignments and choose which ones to work on.\n",
    "\n",
    "**HIT**: Human Intelligence Task - the single unit of work that a Turker would accept. This HIT could be a single task (i.e. \"What is in this image\") or a series of tasks (although that will increase length of time to complete and pay should scale with that factor). For the sake of further discussion we will say that labelling 1 word is 1 HIT and you have 100 words you want to label.\n",
    "\n",
    "**Assignment**: Number of workers that should complete each HIT. If you set Assignment to 2 for 100 word HITs, then you would have 200 assignments. You will want to have an assignment of 3 or more when labelling words to increase confidence in the assigned score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hit coding\n",
    "\n",
    "Hits are ::drumroll please::.....HTML templates :( (Technically it is a HTML page that will be wrapped inside XML, so that's why we save it as `xml`)\n",
    "\n",
    "That's right, you'll need to create a HTML page for your HIT that will be submitted. In its most basic form, it is relatively simple.\n",
    "\n",
    "To make life easier, I separate this into 3 parts: `turk_hit_frontmatter.xml`, `turk_question.html`,`turk_hit_backmatter.xml`. The reason is that you can open the `html` page in a browser and see the result directly.\n",
    "\n",
    "Then to make the final document to submit to AWS, it's just concatenating frontmatter, question, and backmatter to a new file (`backmatter` and `frontmatter` are constant). This front and back matter to the document is pretty simple too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTMLQuestion xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2011-11-11/HTMLQuestion.xsd\">\n",
      "<HTMLContent><![CDATA[\n",
      "\n",
      "----00000 Not in File 00000-------\n",
      "]]>\n",
      "</HTMLContent>\n",
      "<FrameHeight>600</FrameHeight>\n",
      "</HTMLQuestion>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open('turk_hit_frontmatter.xml').read())\n",
    "print('----00000 Not in File 00000-------')\n",
    "print(open('turk_hit_backmatter.xml').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I've coded the simplest turk question possible to pair it with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open turk_question.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the final, submittable question is then relatively simple - it's just putting the three files together into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_turk_xml(turk_html):\n",
    "    fulltext = open('turk_hit_frontmatter.xml').read() + open(turk_html).read() + \\\n",
    "               open('turk_hit_backmatter.xml').read()\n",
    "    return fulltext\n",
    "        \n",
    "fulltext = construct_turk_xml('turk_question.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the task creation is done, we can move to submitting the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://workersandbox.mturk.com/mturk/preview?groupId=3A0F9TXODVNG70NJNMKNP5M1QV1JOJ\n",
      "HITID = 3FTID4TN8KXXR4H9EPVOXTCBW7LYL4 (Use to Get Results)\n"
     ]
    }
   ],
   "source": [
    "new_hit = mturk.create_hit(\n",
    "    Title = 'Is the following word positive, neutral, or negative in emotion?',\n",
    "    Description = 'Read the passage and click the button for the emotion that is attached to the bolded word',\n",
    "    Keywords = 'text, quick, labeling',\n",
    "    Reward = '0.01',\n",
    "    MaxAssignments = 1,\n",
    "    LifetimeInSeconds = 172800,\n",
    "    AssignmentDurationInSeconds = 600,\n",
    "    AutoApprovalDelayInSeconds = 10,\n",
    "    Question = fulltext,\n",
    ")\n",
    "\n",
    "print( \"https://workersandbox.mturk.com/mturk/preview?groupId=\" + new_hit['HIT']['HITGroupId'] )\n",
    "print( \"HITID = \" + new_hit['HIT']['HITId'] + \" (Use to Get Results)\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields mostly speak for themselves at the start. \n",
    "\n",
    "The reward is how much you will pay in USD cents (so this task is for 15 cents).\n",
    "\n",
    "MaxAssignments is the number of turkers you want to complete the HIT\n",
    "\n",
    "LifetimeInSeconds - how long the HIT should be available on the MTurk marketplace\n",
    "\n",
    "AssignmentDurationInSeconds - how long the turker has to complete the HIT once they start the task\n",
    "\n",
    "AutoApprovalDelayInSeconds - You have the ability to manually approve/deny a turker's work (which determines if the worker gets paid). This threshold sets when the system will move from manual to automatic approval (so that if you forget, the turker still gets paid). Note - requesters are rated on a separate forum for turkers and promptness of paying is one attribute that they track. Don't forget about paying in a reasonable amount of time, especially for low cost/risk tasks.\n",
    "\n",
    "Question - what you want them to answer.\n",
    "\n",
    "You can go check out the HIT at the sandbox link (need to register as a turker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excellent**\n",
    "\n",
    "Now (that I have most likely completed my own HIT), we should now be able to pull the data.\n",
    "\n",
    "All will we will need is the client connection to MTurk and the HITID for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Assignments': [{'AcceptTime': datetime.datetime(2018, 1, 30, 16, 42, 11, tzinfo=tzlocal()),\n",
       "   'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>reported_emotion</QuestionIdentifier><FreeText>negative</FreeText></Answer></QuestionFormAnswers>',\n",
       "   'AssignmentId': '33JKGHPFYCUP77TAX1SU49O93NPNMN',\n",
       "   'AssignmentStatus': 'Submitted',\n",
       "   'AutoApprovalTime': datetime.datetime(2018, 1, 30, 16, 42, 24, tzinfo=tzlocal()),\n",
       "   'HITId': '3FTID4TN8KXXR4H9EPVOXTCBW7LYL4',\n",
       "   'SubmitTime': datetime.datetime(2018, 1, 30, 16, 42, 14, tzinfo=tzlocal()),\n",
       "   'WorkerId': 'A2NWOX0S472V5'}],\n",
       " 'NextToken': 'p1:VyseaX/aFy+NGePOPxkuAa5807QioJgFwOZgzThfaEobNij6kk5heellqdCMFg==',\n",
       " 'NumResults': 1,\n",
       " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '660',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 30 Jan 2018 22:42:51 GMT',\n",
       "   'x-amzn-requestid': 'e759a2bc-060e-11e8-9478-9fc06c7e7595'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': 'e759a2bc-060e-11e8-9478-9fc06c7e7595',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_results = mturk.list_assignments_for_hit(HITId=new_hit['HIT']['HITId'])\n",
    "worker_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And my answer is inside the assignments list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AcceptTime': datetime.datetime(2018, 1, 30, 16, 42, 11, tzinfo=tzlocal()),\n",
       " 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>reported_emotion</QuestionIdentifier><FreeText>negative</FreeText></Answer></QuestionFormAnswers>',\n",
       " 'AssignmentId': '33JKGHPFYCUP77TAX1SU49O93NPNMN',\n",
       " 'AssignmentStatus': 'Submitted',\n",
       " 'AutoApprovalTime': datetime.datetime(2018, 1, 30, 16, 42, 24, tzinfo=tzlocal()),\n",
       " 'HITId': '3FTID4TN8KXXR4H9EPVOXTCBW7LYL4',\n",
       " 'SubmitTime': datetime.datetime(2018, 1, 30, 16, 42, 14, tzinfo=tzlocal()),\n",
       " 'WorkerId': 'A2NWOX0S472V5'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_results['Assignments'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we see something ugly - the answer is in the `Answer` field, but it's in XML! \n",
    "\n",
    "Fortunately we can just install the `xmltodict` package which will convert the data out of xml and into something that's friendlier for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in /Users/adampah/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('QuestionIdentifier', 'reported_emotion'),\n",
       "             ('FreeText', 'negative')])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xmltodict\n",
    "\n",
    "xml_doc = xmltodict.parse(worker_results['Assignments'][0]['Answer'])\n",
    "xml_doc['QuestionFormAnswers']['Answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we go! We have our answer - the turker thinks that **unkindly** is *negative*\n",
    "\n",
    "I will leave as an exercise for the reader to figure out how to automatically fill the html template with the passage and word of interest (Hint: manipulate it as a string in python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Accounting for error in our estimates\n",
    "\n",
    "You will now have multiple values for the valence of each word. There are number of ways to handle and process this data. \n",
    "\n",
    "For extemely small or large *n* I am confident that you are well-versed in how to reduce this to a single value (take the mean, check for outliers, etc. - up to you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating quantities the Bayesian way\n",
    "\n",
    "We can assume that there is a true value of the sentiment for a specific word in a single context. We know that the responses, and the spread in them, informs our approximation of the real value and accounts for the uncertainty we have in stating that it is the true value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a Bayesian approach, we are trying to estimate the probability distribution function for the real value (it inherently incorporates uncertainty - which is a good approach when considering something like quantifying the amount of sentiment a word encodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is that we start with some prior knowledge/distribution of 'truth' for a value and then update it as we receive additional information (i.e. mturk responses). \n",
    "\n",
    "<img src='../images/bayes_learn.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, we just need to follow bayes rule\n",
    "\n",
    "$P(A\\mbox{ | }B) = \\frac{P(B\\mbox{ | }A)P(A)}{P(B)}$\n",
    "\n",
    "or stated in a data-centric way\n",
    "\n",
    "$P(Model\\mbox{ | }Data) = \\frac{P(Data\\mbox{ | }Model)P(Model)}{P(Data)}$\n",
    "\n",
    "where the $P(Model)$ is prior probability for our model and $P(Model\\mbox{ | }Data)$ is our posterior probability after we have incorporated the data. $P(Data\\mbox{ | }Model)$ is simply the probability of observing the data given our current model and $P(Data)$ is the marginal likelihood (which is the same for all models under consideration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sounds complicated?\n",
    "\n",
    "Fortunately, it's not that hard in practice. There are two ways to go about this - the first that I want you to explore is by hand with scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "\n",
    "#Set the likelihood\n",
    "likelihood = np.array([])\n",
    "#Set our supports\n",
    "params = np.linspace(-6, 6, 1201)\n",
    "#And initialize the posterior\n",
    "posterior = np.array([])\n",
    "#Construct the prior\n",
    "prior_sample = np.random.normal(0, 0.2)\n",
    "prior = np.array([np.product(st.norm.pdf(prior_sample, p)) for p in params])\n",
    "prior = prior / np.sum(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1273a89b0>]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkRsGXzM6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1272ea4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_probability(datapoint, likelihood, prior, posterior, params):\n",
    "    likelihood = np.array([np.product(st.norm.pdf([datapoint], p)) for p in params])\n",
    "    #Construct the posterior\n",
    "    tposterior = [prior[i] * likelihood[i] for i in range(prior.shape[0])]\n",
    "    posterior = tposterior / np.sum(tposterior)\n",
    "    #Reset the prior to the new posterior\n",
    "    prior = np.copy(posterior)\n",
    "    return likelihood, prior, posterior\n",
    "\n",
    "for i in range(100):\n",
    "    likelihood, prior, posterior = update_probability(0.4, likelihood, prior, posterior, params)\n",
    "plt.plot(params, posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Alternatively, you could use a package that implements Bayesian data fitting (such as pymc or emcee), instead of coding it yourself to estimate the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
